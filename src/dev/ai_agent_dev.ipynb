{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test AI Angent Work flow for Bank Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnsonhk88/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os, json, time, gc\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import HTML, Markdown, Image, Video\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "\n",
    "#fix bug with aysncio and jupyter\n",
    "import nest_asyncio # for langchain async \n",
    "nest_asyncio.apply()\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    OFFLINE = False #True # for Test offline environment\n",
    "    USE_LLAMA3 = False # \n",
    "    USE_GEMMA2 = False # \n",
    "    USE_QWEN = False # \n",
    "    USE_DEEPSEEK = True # \n",
    "    USE_DEEPSCALE = False # \n",
    "\n",
    "    TASK_GEN = True # for generative Text output task (suitable for RAG project)\n",
    "    TEST_LLM = True\n",
    "    USE_HUGGINGFACE = True # Pull model from Huggingface model hub\n",
    "    USE_LMSTUIDO = False # for local LLM framework \n",
    "    USE_OLLAMA = False # for OLLAMA local LLM framework \n",
    "    USE_VLLM = False # for VLLM  LLM framework\n",
    "\n",
    "    # mulitlingual LLM model \n",
    "    model1 = \"meta-llama/Llama-3.2-3B-Instruct\"  # llama3.2  3B-Instruct\n",
    "\n",
    "    model2 =  \"google/gemma-2-2b-it\" # gemma 2 9B (mulitlingual)\n",
    "    model3 = \"Qwen/Qwen2.5-3B-Instruct\" # Qwen 3B (mulitlingual)\n",
    "    model4 = 'Qwen/Qwen2.5-7B-Instruct' # Qwen 7B (mulitlingual)\n",
    "    model5 = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\" # DeepSeek Distill 1.5B (mulitlingual)\n",
    "    model6 = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\" # DeepSeek Distill 7B (mulitlingual)\n",
    "    model7 = \"agentica-org/DeepScaleR-1.5B-Preview\"\n",
    "\n",
    "    # for VLM model\n",
    "    vlmModel1 = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "    vlmModel2 = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "\n",
    "    # Mult Embedding model\n",
    "    embedModel1 = 'intfloat/multilingual-e5-small' # for embedding model support chinese\n",
    "    embedModel2 = \"intfloat/multilingual-e5-large-instruct\"\n",
    "    embedModel3 = \"Alibaba-NLP/gte-Qwen2-1.5B-instruct\" # for embedding model support chinese\n",
    "    embedModel4 = \"Alibaba-NLP/gte-multilingual-base\" # for embedding model support chinese\n",
    "    embedModel5 = \"BAAI/bge-m3\" # for multilingual embedding model\n",
    "    embedModel6 = \"jinaai/jina-embeddings-v3\"\n",
    "    \n",
    "\n",
    "    # LLM for AI Agent \n",
    "    llmModel1 = \"ollama/deepseek-r1:8b\"\n",
    "    llm_base_url1 = \"http://localhost:11434\"\n",
    "\n",
    "\n",
    "    FEW_SHOT_TEST= False#True\n",
    "    USE_WANDB = True#True # for  LLM evalution and debug , track fine tuning performance\n",
    "\n",
    "    USE_DEEPEVAL = True#False # for LLM evalution   \n",
    "    USE_TRAIN =  False #True #False#True Much be use GPU for Training \n",
    "    \n",
    "    # For VectorDB selection\n",
    "    USE_FAISS = False#True # For RAG VectorDB\n",
    "    USE_CHROMA = True #False #True #False # for RAG VectorDF\n",
    "    USE_PINECONE = False#True#False #True # for RAG VectorDF\n",
    "    USE_WEAVIATE = False#True #False # for RAG VectorDF\n",
    "    USE_MILVUS = False#True              # for RAG VectorDF\n",
    "\n",
    "    # for LLM fine tuning\n",
    "    maxTrainData = 200#3500#5000 #10000#5000 #10000\n",
    "    maxEvalData = 20#100 # 20 \n",
    "\n",
    "\n",
    "    # LLM parameters\n",
    "    reportTo =\"none\"\n",
    "    topK = 40\n",
    "    topP = 1.0\n",
    "    temperature = 0.6 #0.5\n",
    "    repetition_penalty = 1.05 # 1.1\n",
    "    maxOutToken = 1024#180 #100\n",
    "    \n",
    "\n",
    "    \n",
    "    maxToken=  512#768#512#768 # 512 for test only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnsonhk88/.local/lib/python3.10/site-packages/pydantic/_internal/_config.py:295: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
      "/usr/lib/python3/dist-packages/paramiko/pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/usr/lib/python3/dist-packages/paramiko/transport.py:237: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 45.0.0.\n",
      "  \"class\": algorithms.Blowfish,\n",
      "/usr/lib/python3/dist-packages/paramiko/transport.py:261: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "/home/johnsonhk88/.local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"schema\" in \"DatabricksQueryToolSchema\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/home/johnsonhk88/.local/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:502: UserWarning: <built-in function callable> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "/home/johnsonhk88/.local/lib/python3.10/site-packages/crewai_tools/tools/scrapegraph_scrape_tool/scrapegraph_scrape_tool.py:34: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "/home/johnsonhk88/.local/lib/python3.10/site-packages/crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py:26: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "/home/johnsonhk88/.local/lib/python3.10/site-packages/crewai_tools/tools/vision_tool/vision_tool.py:15: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"image_path_url\")\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import ScrapeWebsiteTool, SerperDevTool\n",
    "from crewai.tools import BaseTool, tool\n",
    "from crewai import LLM\n",
    "import crewai\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Type\n",
    "from crewai_tools import PDFSearchTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrewAI Support LLM List :  LiteLLM \n",
    "- <https://docs.crewai.com/how-to/llm-connections>\n",
    "- <https://docs.crewai.com/concepts/llms>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    model= CFG.llmModel1,\n",
    "    base_url= CFG.llm_base_url1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "document_agent = Agent( role=\"Extract Document Agent\",\n",
    "    goal=\"Extract information from a document\",\n",
    "    backstory=\"You are a document extraction agent. You will be given a document and you need to extract the relevant information from it.\",\n",
    "    # tools=[webSearchTool],\n",
    "    llm=llm,\n",
    "    max_iter=10,\n",
    "    allow_delegation= True,\n",
    "    verbose=True,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_agent = Agent( role=\"RAG Agent\",\n",
    "                  goal=\"Extract information from a document\",\n",
    "                 backstory=(\"You are a document retrieval agent.\"\n",
    "                              \"You will be given a document and you need to extract the relevant information from it.\"),\n",
    "                 llm=llm,\n",
    "                 allow_delegation= True,\n",
    "                 verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiancial_agent = Agent( role= \"Personal Finance Analystic Expert\",\n",
    "                        goal=\"Extract information from a document\",\n",
    "                        backstory=(\"You are a document retrieval agent.\"\n",
    "                                   \"You will be given a document and you need to extract the relevant information from it.\"),\n",
    "                        # tools=[webSearchTool],\n",
    "                        llm=llm,\n",
    "                        max_iter=10,\n",
    "                        allow_delegation= True,\n",
    "                        verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_agent = Agent( role= \"Report Expert for Financial Analystic\",\n",
    "                      goal=\"\",\n",
    "                      backstory=(\"\"),\n",
    "                     \n",
    "                     )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
